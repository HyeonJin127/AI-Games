*AI í´ë”ì•ˆì—ì„œ ì‹¤í–‰*
### python -m venv .venv <- .venv ê°€ìƒí™˜ê²½ ìƒì„±
### .venv\Scripts\activate
### pip install -r requirements.txt 

### .venv\Scripts\activate <- ê°€ìƒí™˜ê²½ ì‹¤í–‰

-------------------------

1. í•™ìŠµ ë°ì´í„° ìƒì„± ìœ„ì¹˜

train_qlearning.pyë¥¼ ì‹¤í–‰í•˜ë©´, í•™ìŠµì´ ëë‚œ í›„
ë‹¤ìŒ íŒŒì¼ë“¤ì´ í”„ë¡œì íŠ¸ í´ë” (mazes/) ì— ìƒì„±ëœë‹¤.

mazes/
â”œâ”€ qtable.pkl
â”œâ”€ rewards.csv

---------------------------

2. qtable.pkl (ê°•í™”í•™ìŠµ í•µì‹¬ ë°ì´í„°)
âœ… ì—­í• 

AI1(Q-learning ì—ì´ì „íŠ¸)ì˜ í•™ìŠµ ê²°ê³¼(ì •ì±…, policy) ë¥¼ ì €ì¥í•œ íŒŒì¼

ë‚œì´ë„ ì„ íƒ ë° ëª¨ë¸ ë¡œë”©ê³¼ ì§ì ‘ì ìœ¼ë¡œ ì—°ê´€ë˜ëŠ” í•µì‹¬ ë°ì´í„°

âœ… íŒŒì¼ ì •ë³´

ìœ„ì¹˜: mazes/qtable.pkl

í˜•ì‹: Python dictë¥¼ pickleë¡œ ì§ë ¬í™”í•œ ë°”ì´ë„ˆë¦¬ íŒŒì¼

---------------------------

3. Q-table ë‚´ë¶€ êµ¬ì¡°

train_qlearning.pyì—ì„œ Q-tableì€ ë‹¤ìŒê³¼ ê°™ì´ ì„ ì–¸ë¨:

Q = defaultdict(float)

ğŸ”¹ Key / Value êµ¬ì¡°

Key: (state, action)

state : (x, y) â†’ AI1ì˜ í˜„ì¬ ë¯¸ë¡œ ì¢Œí‘œ

action: int â†’ ì´ë™ ë°©í–¥

0: UP

1: DOWN

2: LEFT

3: RIGHT

Value: float

í•´ë‹¹ ìƒíƒœì—ì„œ í•´ë‹¹ í–‰ë™ì„ ì„ íƒí–ˆì„ ë•Œì˜ Q-value

ğŸ”¹ ê°œë…ì  í…Œì´ë¸” í˜•íƒœ
x	y	action	q_value
1	1	0	0.13
1	1	1	-0.05
2	1	2	1.27
â€¦	â€¦	â€¦	â€¦
ğŸ”¹ ì‹¤ì œ ë…¼ë¦¬ êµ¬ì¡°
Q[((x, y), action)] = q_value


í•™ìŠµì´ ëë‚˜ë©´ ë‹¤ìŒ ì½”ë“œë¡œ íŒŒì¼ì— ì €ì¥ë¨:

plain_q = dict(Q)
pickle.dump(plain_q, f)   # qtable.pkl

---------------------------

4. rewards.csv (í•™ìŠµ ì„±ëŠ¥ ë¡œê·¸)
âœ… ì—­í• 

ì—í”¼ì†Œë“œë³„ ì´ ë¦¬ì›Œë“œ ê¸°ë¡

í•™ìŠµ ì„±ëŠ¥ ë¶„ì„ ë° ê·¸ë˜í”„ ì‹œê°í™” ìš©ë„

âœ… êµ¬ì¡° ì˜ˆì‹œ
episode,reward
1,-32.4
2,-21.5
3,-18.0
...
300,8.0


âš  ë‚œì´ë„ ì„ íƒì—ëŠ” ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
(ë¶„ì„/ë¦¬í¬íŠ¸/ì‹œê°í™” ëª©ì )

---------------------------

5. ë‚œì´ë„ ì„ íƒ & DB ì €ì¥ ì„¤ê³„ ê°€ì´ë“œ

í˜„ì¬ëŠ” íŒŒì¼ ê¸°ë°˜(pickle) ì €ì¥ì´ì§€ë§Œ,
ë‚œì´ë„ ì„ íƒ ê¸°ëŠ¥ì„ ìœ„í•´ DBë¡œ í™•ì¥í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°ê°€ ë‹¨ìˆœí•˜ê²Œ ì„¤ê³„ë¨.

âœ… DB í…Œì´ë¸” ì„¤ê³„ ì˜ˆì‹œ
ì»¬ëŸ¼ëª…	ì„¤ëª…
difficulty	ë‚œì´ë„ (easy / normal / hard)
x	AI1 ìœ„ì¹˜ x
y	AI1 ìœ„ì¹˜ y
action	í–‰ë™ (0~3)
q_value	Q-value
âœ… ë‚œì´ë„ë³„ ì •ì±… ê´€ë¦¬ ë°©ì‹

ë‚œì´ë„ë³„ë¡œ ë‹¤ë¥¸ Q-table(ì •ì±…) ì‚¬ìš© ê°€ëŠ¥

EASY â†’ Q_easy

NORMAL â†’ Q_normal

HARD â†’ Q_hard

âœ… ê²Œì„ ì‹¤í–‰ íë¦„ (ë‚˜ì¤‘ ë‹¨ê³„)

í”Œë ˆì´ì–´ê°€ ë‚œì´ë„ ì„ íƒ

DBì—ì„œ í•´ë‹¹ ë‚œì´ë„ì˜ Q-table ë¡œë“œ

(x, y, action) â†’ q_value í˜•íƒœë¡œ ì¬êµ¬ì„±

main.pyì—ì„œ Q-table ê¸°ë°˜ ì •ì±…ìœ¼ë¡œ AI1 ì‹¤í–‰

---------------------------

# í•œì¤„ì •ë¦¬

í•™ìŠµ ê²°ê³¼ëŠ” qtable.pkl íŒŒì¼ì— ì €ì¥ë˜ë©°,
(x, y, action) â†’ q_value í˜•íƒœì˜ Q-table(dict)ë¡œ êµ¬ì„±ëœ
ê°•í™”í•™ìŠµ(Q-learning) ì •ì±… ë°ì´í„°ì´ë‹¤.
